{"cells":[{"cell_type":"markdown","metadata":{"id":"niLkXiDphVuE"},"source":["# Lab 10.1: Tumbling Window Demo\n","\n","## Tổng quan bài tập\n","**Đề bài**: Ở bài Lab này, bạn sẽ được hướng dẫn các thao tác để sử dụng cơ chế Tumbling Window trong Spark. Giúp tính toán tổng các giá trị Mua và Bán theo từng khoảng thời gian cách nhau **15 phút** như sau:\n","\n","\n","<img src='https://firebasestorage.googleapis.com/v0/b/funix-way.appspot.com/o/xSeries%2FData%20Engineer%2FDEP303x%2FSumary_Image%2FDEP303_sum_L14_1.png?alt=media&token=9ecf978e-6d45-4aa8-b802-5e4039fbf1d3'>\n","\n","\n","## Tài nguyên\n","Do bài Lab này liên quan đến đến xử lý dữ liệu Stream với Kafka, vậy nên bạn sẽ cần cài đặt Kafka, bạn có thể tham khảo video sau về cách cài đặt:\n","- [Cài đặt Kafka](https://funix.udemy.com/course/spark-streaming-using-python/learn/lecture/21955580#overview)\n","\n","Bạn sẽ cần tải các Kafka Script ở [link sau](https://drive.google.com/file/d/1VXXedZ343pkESVlP5R8CMkX_cmqmgjJi/view?usp=sharing) để có thể sử dụng Kafka.\n","\n","\n","Bạn cũng sẽ cần tải các dữ liệu ở [link sau](https://drive.google.com/file/d/1MYqXxRfGY9MxWamvCXTh9XnsFnAIwwGz/view?usp=sharing) để có thể kiểm thử cho bài Lab.\n","\n","Ngoài ra, bạn có thể tham khảo các video sau trong trường hợp chưa hiểu cách làm bài Lab:\n","- [Tumbling Window](https://funix.udemy.com/course/spark-streaming-using-python/learn/lecture/21955638#overview)\n"]},{"cell_type":"markdown","metadata":{"id":"fIvm5a2AhVuH"},"source":["Import các Package cần thiết"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nvgy7mnHhVuI"},"outputs":[],"source":["from pyspark.sql import SparkSession, Window\n","from pyspark.sql.functions import from_json, col, to_timestamp, window, expr, sum\n","from pyspark.sql.types import StructType, StructField, StringType, IntegerType"]},{"cell_type":"markdown","metadata":{"id":"4pfMvTDchVuJ"},"source":["Khởi tạo Spark Session"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lnEnipUqhVuJ"},"outputs":[],"source":["spark = SparkSession \\\n","\t.builder \\\n","\t.appName(\"lab10 Tumbling Window Demo\") \\\n","\t.master(\"local[3]\") \\\n","\t.config(\"spark.streaming.stopGracefullyOnShutdown\", \"true\") \\\n","\t.config(\"spark.sql.shuffle.partitions\", 2) \\\n","\t.getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"2J6Tk1owhVuJ"},"source":["Tạo schema cho dữ liệu đầu vào"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mh6pkbndhVuK"},"outputs":[],"source":["stock_schema = StructType([\n","  StructField(\"CreatedTime\", StringType()),\n","  StructField(\"Type\", StringType()),\n","  StructField(\"Amount\", IntegerType()),\n","  StructField(\"BrokerCode\", StringType())\n","])"]},{"cell_type":"markdown","metadata":{"id":"7Sy2tx2dhVuL"},"source":["Hãy hoàn thiện các phần `[...]` để hoàn thiện đoạn code và giải quyết bài toán theo yêu cầu."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"znR7LrpyhVuL"},"outputs":[],"source":["# Đọc dữ liệu từ Kafka\n","kafka_df = spark.readStream \\\n","\t.format(\"kafka\") \\\n","\t.option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n","\t.option(\"subscribe\", \"trades\") \\\n","\t.option(\"startingOffsets\", \"earliest\") \\\n","\t.load()\n","\n","# Chuyển dữ liệu từ dạng JSON về MapType()\n","value_df = kafka_df.select(from_json(col(\"value\").cast(\"string\"), stock_schema).alias(\"value\"))\n","\n","# Trích xuất các dữ liệu\n","trade_df = value_df.select(\"value.*\") \\\n","\t.withColumn(\"CreatedTime\", to_timestamp(col(\"CreatedTime\"), \"yyyy-MM-dd HH:mm:ss\")) \\\n","\t.withColumn(\"Buy\", expr(\"case when Type == 'BUY' then Amount else 0 end\")) \\\n","\t.withColumn(\"Sell\", expr(\"case when Type == 'SELL' then Amount else 0 end\"))\n","\n","# Sử dụng cơ chế Tumbling Window\n","window_agg_df = trade_df \\\n","\t.groupBy(\n","\t\twindow(col(\"CreatedTime\"), \"15 minute\")) \\\n","\t.agg(sum(\"Buy\").alias(\"TotalBuy\"),\n","\t\t\tsum(\"Sell\").alias(\"TotalSell\"))\n","\n","# Ghi dữ liệu đã xử lý\n","output_df = window_agg_df.select(\"window.start\", \"window.end\", \"TotalBuy\", \"TotalSell\")\n","\n","window_query = output_df.writeStream \\\n","\t.format(\"console\") \\\n","\t.outputMode(\"update\") \\\n","\t.option(\"checkpointLocation\", \"chk-point-dir\") \\\n","\t.trigger(processingTime=\"1 minute\") \\\n","\t.start()\n","\n","print(\"Waiting for Query\")\n","window_query.awaitTermination()"]}],"metadata":{"colab":{"provenance":[]},"interpreter":{"hash":"67e442376543da31be6bdf2ca3edab58a905f904bfaaefbdb9d9ed4ba9c6bc77"},"kernelspec":{"display_name":"Python 3.8.10 64-bit ('big-data': venv)","name":"python3"},"language_info":{"name":"python","version":"3.12.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
