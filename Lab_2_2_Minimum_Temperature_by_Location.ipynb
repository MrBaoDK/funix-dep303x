{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9csAsqvcOsD"
      },
      "source": [
        "# Lab 2.2: Minimum Temperature by Location\n",
        "\n",
        "## Tổng quan bài tập\n",
        "**Đề bài**: Dựa vào tập dữ liệu, hãy tìm nhiệt độ `TMIN` thấp nhất theo từng khu vực. Hãy hoàn thiện các phần `[...]` để hoàn thiện đoạn code và giải quyết bài toán trên.\n",
        "\n",
        "## Tài nguyên tham khảo\n",
        "\n",
        "Bạn có thể tải tập Dataset tại [link sau](https://drive.google.com/file/d/1fLLX1e4Wd_Ks-0u9iRfJipVTqsVm0Kzp/view?usp=sharing). Sau đó đưa lên Google Drive và kết nối với Colab là có thể sử dụng được. Tập dữ liệu là file .csv gồm 4 cột theo thứ tự sau:\n",
        "- `StationID`: Mã thành phố.\n",
        "- `Date`: Thời gian.\n",
        "- `Type`: Loại nhiệt độ (`TMAX` hoặc `TMIN`) tương ứng với nhiệt độ cao nhát hoặc thấp nhất trong ngày đó.\n",
        "- `Temperature`: Giá trị nhiệt độ.\n",
        "\n",
        "Ngoài ra, bạn có thể tham khảo các video sau trong trường hợp chưa hiểu cách làm bài Lab:\n",
        "- [Minimum Temperature by Location](https://fpt-software.udemy.com/course/taming-big-data-with-apache-spark-hands-on/learn/lecture/3719528#overview)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPRu5D4IfO3I"
      },
      "source": [
        "# Cài đặt Spark trên Google Colab\n",
        "\n",
        "Để có thể sử dụng Spark trên môi trường Google Colab thì bạn sẽ cần cài đặt một số thành phần sau:\n",
        "- Java 8\n",
        "- Spark Binary\n",
        "- findspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHdKMp8zeMel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68432597-89b0-49aa-f303-d04bafa06837"
      },
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r            \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [632 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,265 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,494 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,027 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,520 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,535 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,291 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [32.6 kB]\n",
            "Fetched 9,138 kB in 2s (3,672 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "17 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fv63ddnSOG-"
      },
      "source": [
        "Sau đó, bạn sẽ cần khai báo cho hệ thống các đường dẫn cho các thành phần vừa cài."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8gN9Zhx8vPb"
      },
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "findspark.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM4wpiJMTCib"
      },
      "source": [
        "# Kết nối với Google Drive\n",
        "\n",
        "Để lấy dữ liệu từ các Dataset, bạn sẽ phải lưu file dữ liệu lên Google Drive. Sau đó kết nối Colab đến Google Drive của bạn và lấy được các file dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoYnrNV7UChX",
        "outputId": "0745c196-c5f1-4e14-e061-f469617af1bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-DVTOmPmYaK"
      },
      "source": [
        "# Minimum Temperature by Location\n",
        "\n",
        "Bạn sẽ cần khởi tạo 1 SparkSesson để có thể bắt đầu Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjqT5XXj80P8"
      },
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "conf = SparkConf() \\\n",
        "    .setMaster('local') \\\n",
        "    .setAppName('lab2.2')\n",
        "\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d-ojhFfr5Gi"
      },
      "source": [
        "Đọc dữ liệu từ Dataset và lưu vào RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEiMOpueMB6O"
      },
      "source": [
        "DATASET_PATH = '/content/gdrive/My Drive/DEP303/1800.csv'\n",
        "lines = sc.textFile(DATASET_PATH)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2J1sAcYsAte"
      },
      "source": [
        "Sau đó sẽ chuyển đổi dữ liệu thành các cặp Key-Vaule tương ứng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iXFCl_TsB_Q"
      },
      "source": [
        "def parseLine(line):\n",
        "    cells = line.split(',')\n",
        "    stationID = cells[0]\n",
        "    entryType = cells[2]\n",
        "    # Chuyển đổi nhiệt độ về độ F\n",
        "    temperature = float(cells[3]) * 0.1 * (9.0 / 5.0) + 32.0\n",
        "    return (stationID, entryType, temperature)\n",
        "\n",
        "parsedLines = lines.map(parseLine)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5eLDbdgmcoE",
        "outputId": "28f36f44-7022-43c2-afea-00de6df62519"
      },
      "source": [
        "# Lọc các giá trị có Type là TMIN\n",
        "minTemps = parsedLines.filter(lambda x: x[1]=='TMIN')\n",
        "\n",
        "# Tìm giá trị nhiệt độ nhỏ nhất theo các thành phố.\n",
        "stationTemps = minTemps.map(lambda x: (x[0], x[2]))\n",
        "minTemps = stationTemps.reduceByKey(lambda x, y: min(x, y))\n",
        "\n",
        "results = minTemps.collect();\n",
        "for result in results:\n",
        "    print(result[0] + \"\\t{:.2f}F\".format(result[1]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ITE00100554\t5.36F\n",
            "EZE00100082\t7.70F\n"
          ]
        }
      ]
    }
  ]
}