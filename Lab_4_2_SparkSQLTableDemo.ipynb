{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaL70vgSqsqe"
      },
      "source": [
        "# Lab4.2: SparkSQLTableDemo\n",
        "\n",
        "## Tổng quan bài tập\n",
        "**Đề bài**: Ở bài Lab này, bạn sẽ được thực hành về việc tạo một Spark Table. Hãy hoàn thiện các phần `[...]` để hoàn thiện đoạn code theo yêu cầu.\n",
        "\n",
        "## Tài nguyên tham khảo\n",
        "\n",
        "Bạn có thể tải tập Dataset tại [link sau](https://drive.google.com/file/d/1QntwdBjL6T9S6kNbOckYLLYIRCuBpeUu/view?usp=sharing). Sau đó đưa lên Google Drive và kết nối với Colab là có thể sử dụng được. Tập dữ liệu là file .csv có cấu trúc như sau:\n",
        "```\n",
        "root\n",
        " |-- FL_DATE: date (nullable = true)\n",
        " |-- OP_CARRIER: string (nullable = true)\n",
        " |-- OP_CARRIER_FL_NUM: integer (nullable = true)\n",
        " |-- ORIGIN: string (nullable = true)\n",
        " |-- ORIGIN_CITY_NAME: string (nullable = true)\n",
        " |-- DEST: string (nullable = true)\n",
        " |-- DEST_CITY_NAME: string (nullable = true)\n",
        " |-- CRS_DEP_TIME: integer (nullable = true)\n",
        " |-- DEP_TIME: integer (nullable = true)\n",
        " |-- WHEELS_ON: integer (nullable = true)\n",
        " |-- TAXI_IN: integer (nullable = true)\n",
        " |-- CRS_ARR_TIME: integer (nullable = true)\n",
        " |-- ARR_TIME: integer (nullable = true)\n",
        " |-- CANCELLED: integer (nullable = true)\n",
        " |-- DISTANCE: integer (nullable = true)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPRu5D4IfO3I"
      },
      "source": [
        "# Cài đặt Spark trên Google Colab\n",
        "\n",
        "Để có thể sử dụng Spark trên môi trường Google Colab thì bạn sẽ cần cài đặt một số thành phần sau:\n",
        "- Java 8\n",
        "- Spark Binary\n",
        "- findspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHdKMp8zeMel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1c47a6-2cdd-4f9b-be7f-9f561402bac9"
      },
      "source": [
        "!sudo apt update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz\n",
        "!tar xf spark-3.5.0-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,617 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,309 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,258 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,158 kB]\n",
            "Fetched 6,594 kB in 2s (2,700 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "25 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fv63ddnSOG-"
      },
      "source": [
        "Sau đó, bạn sẽ cần khai báo cho hệ thống các đường dẫn cho các thành phần vừa cài."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8gN9Zhx8vPb"
      },
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.0-bin-hadoop3\"\n",
        "\n",
        "findspark.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM4wpiJMTCib"
      },
      "source": [
        "# Kết nối với Google Drive\n",
        "\n",
        "Để lấy dữ liệu từ các Dataset, bạn sẽ phải lưu file dữ liệu lên Google Drive. Sau đó kết nối Colab đến Google Drive của bạn và lấy được các file dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoYnrNV7UChX",
        "outputId": "92072e6f-d336-4b46-9796-7f32d794e270"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0yzaQQNDKoV"
      },
      "source": [
        "# SparkSQLTableDemo\n",
        "\n",
        "Bạn sẽ cần khởi tạo 1 SparkSesson để có thể bắt đầu Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjqT5XXj80P8"
      },
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "conf = SparkConf() \\\n",
        "    .setMaster('local') \\\n",
        "    .setAppName('SparkSQLTableDemo')\n",
        "\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "DATASET_PATH = '/content/gdrive/My Drive/DEP303/flight-time.parquet'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQJVPEB3CUIJ"
      },
      "source": [
        "Tạo một Managed Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EP8NFncoDbX4",
        "outputId": "b0fbbc32-6c34-40de-cac4-0a651770634b"
      },
      "source": [
        "# Đọc dữ liệu từ Dataset\n",
        "flightTimeParquetDF = spark.read \\\n",
        "    .format(\"parquet\") \\\n",
        "    .load(DATASET_PATH)\n",
        "\n",
        "# Tạo Database \"AIRLINE_DB\" nếu chưa tồn tại\n",
        "spark.sql(\"CREATE DATABASE IF NOT EXISTS AIRLINE_DB\")\n",
        "spark.catalog.setCurrentDatabase(\"AIRLINE_DB\")\n",
        "\n",
        "flightTimeParquetDF.write \\\n",
        "    .mode(\"overwrite\") \\\n",
        "    .saveAsTable(\"flight_data_tbl\")\n",
        "\n",
        "print(spark.catalog.listTables(\"AIRLINE_DB\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Table(name='flight_data_tbl', catalog='spark_catalog', namespace=['airline_db'], description=None, tableType='MANAGED', isTemporary=False)]\n"
          ]
        }
      ]
    }
  ]
}